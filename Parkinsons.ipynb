{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k689iI0ps_4q",
        "outputId": "5512051e-dff0-4512-e599-a8b1981aeb98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PARKINSON'S DISEASE CLASSIFICATION - COMPLETE PIPELINE\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, learning_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, confusion_matrix,\n",
        "                             classification_report)\n",
        "import time\n",
        "import psutil\n",
        "import os\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuration\n",
        "DATASET_PATH = \"parkinsons.data\"\n",
        "TARGET_COLUMN = \"status\"\n",
        "OUTPUT_DIR = \"parkinsons_outputs\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"PARKINSON'S DISEASE CLASSIFICATION - COMPLETE PIPELINE\\n\")\n",
        "\n",
        "\n",
        "# SECTION 1: DATA LOADING\n",
        "def load_data(path):\n",
        "\n",
        "\n",
        "    df = pd.read_csv(path)\n",
        "    print(f\"Dataset loaded successfully\")\n",
        "    print(f\"Shape: {df.shape} (rows x columns)\")\n",
        "    print(f\"Features: {df.shape[1]}\")\n",
        "\n",
        "    print(f\"\\nData Types:\")\n",
        "    print(df.dtypes.value_counts())\n",
        "\n",
        "    print(f\"\\nFirst 5 rows:\")\n",
        "    print(df.head())\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "hIApTLDdt0_X"
      },
      "outputs": [],
      "source": [
        "# SECTION 2: DATA CLEANING WITH FEATURE SELECTION\n",
        "def clean_data(df):\n",
        "    \"\"\"\n",
        "    Enhanced cleaning function with correlation-based feature selection\n",
        "    to reduce overfitting\n",
        "    \"\"\"\n",
        "    print(\"\\n2. DATA CLEANING WITH FEATURE SELECTION\\n\")\n",
        "\n",
        "    print(f\"Before cleaning: {df.shape}\")\n",
        "\n",
        "    # Drop identifier column\n",
        "    if 'name' in df.columns:\n",
        "        df = df.drop(columns=['name'])\n",
        "        print(\"Removed 'name' column (identifier)\")\n",
        "\n",
        "    # Remove duplicates\n",
        "    original_rows = len(df)\n",
        "    df = df.drop_duplicates()\n",
        "    duplicates_removed = original_rows - len(df)\n",
        "    print(f\"Removed {duplicates_removed} duplicate rows\")\n",
        "\n",
        "    # Handle missing values\n",
        "    missing = df.isnull().sum()\n",
        "    if missing.sum() > 0:\n",
        "        print(f\"\\nMissing values found:\")\n",
        "        print(missing[missing > 0])\n",
        "\n",
        "        numeric_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
        "        numeric_cols = [col for col in numeric_cols if col != TARGET_COLUMN]\n",
        "        df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
        "        print(\"Filled missing values with median\")\n",
        "    else:\n",
        "        print(\"No missing values found\")\n",
        "\n",
        "    print(f\"\\nAfter basic cleaning: {df.shape}\")\n",
        "\n",
        "\n",
        "    print(\"CORRELATION-BASED FEATURE SELECTION\")\n",
        "\n",
        "\n",
        "    target = TARGET_COLUMN\n",
        "    X = df.drop(columns=[target])\n",
        "    y = df[target]\n",
        "\n",
        "    original_feature_count = len(X.columns)\n",
        "\n",
        "    # Calculate correlations with target\n",
        "    print(\"\\nCalculating correlations with target variable...\")\n",
        "    correlations = df.corr()[target].abs().sort_values(ascending=False)\n",
        "\n",
        "    # Remove target itself and select top 15\n",
        "    correlations = correlations[correlations.index != target]\n",
        "    top_15_features = correlations.head(15).index.tolist()\n",
        "\n",
        "    print(f\"\\nTop 15 Features by Correlation with '{target}':\")\n",
        "    print(\"-\" * 60)\n",
        "    for idx, feat in enumerate(top_15_features, 1):\n",
        "        corr_val = correlations[feat]\n",
        "        print(f\"   {idx:2d}. {feat:30s} | Correlation: {corr_val:.4f}\")\n",
        "\n",
        "    # Create final dataframe with selected features\n",
        "    df_final = df[top_15_features + [target]]\n",
        "\n",
        "\n",
        "\n",
        "    print(\"FEATURE SELECTION SUMMARY\")\n",
        "\n",
        "    print(f\"Original features:  {original_feature_count}\")\n",
        "    print(f\"Selected features:  15\")\n",
        "    print(f\"Reduction:  {original_feature_count - 15} features removed ({(original_feature_count - 15)/original_feature_count*100:.1f}%)\")\n",
        "    print(f\"\\nFinal shape: {df_final.shape}\")\n",
        "    print(f\"Final features: {df_final.shape[1] - 1} (excluding target)\")\n",
        "\n",
        "    return df_final"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SECTION 3: EXPLORATORY DATA ANALYSIS\n",
        "def run_eda(df, target_col='status'):\n",
        "    \"\"\"Comprehensive EDA with visualizations including PPE scatterplot\"\"\"\n",
        "    print(\"\\n3. EXPLORATORY DATA ANALYSIS\")\n",
        "\n",
        "    eda_dir = f\"{OUTPUT_DIR}/eda_plots\"\n",
        "    os.makedirs(eda_dir, exist_ok=True)\n",
        "\n",
        "    # Target distribution\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    target_counts = df[target_col].value_counts().sort_index()\n",
        "    colors = ['#3498db', '#e74c3c']\n",
        "    bars = plt.bar(target_counts.index, target_counts.values, color=colors,\n",
        "                   edgecolor='black', width=0.6)\n",
        "    plt.title('Parkinson\\'s Disease Status Distribution', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Status (0=Healthy, 1=Parkinson\\'s)')\n",
        "    plt.ylabel('Count')\n",
        "    plt.xticks([0, 1], ['Healthy', 'Parkinson\\'s'])\n",
        "    for bar, (idx, v) in zip(bars, target_counts.items()):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, v + len(df)*0.01,\n",
        "                f'{v}\\n({v/len(df)*100:.1f}%)',\n",
        "                ha='center', fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{eda_dir}/01_target_distribution.png\", dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(\"Saved: 01_target_distribution.png\")\n",
        "\n",
        "    # PPE Scatterplot (Most Important Feature)\n",
        "    if 'PPE' in df.columns:\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        # Create scatterplot with index on x-axis\n",
        "        healthy = df[df[target_col] == 0]\n",
        "        parkinsons = df[df[target_col] == 1]\n",
        "\n",
        "        plt.scatter(healthy.index, healthy['PPE'], c='#3498db', label='Healthy',\n",
        "                   alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
        "        plt.scatter(parkinsons.index, parkinsons['PPE'], c='#e74c3c', label='Parkinson\\'s',\n",
        "                   alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
        "\n",
        "        plt.title('PPE (Pitch Period Entropy) - Most Important Feature',\n",
        "                 fontsize=14, fontweight='bold')\n",
        "        plt.xlabel('Sample Index')\n",
        "        plt.ylabel('PPE Value')\n",
        "        plt.legend()\n",
        "        plt.grid(alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{eda_dir}/02_ppe_scatterplot.png\", dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "        print(\"Saved: 02_ppe_scatterplot.png (PPE scatterplot)\")\n",
        "\n",
        "        # Additional PPE analysis\n",
        "        print(f\"\\nPPE Statistics:\")\n",
        "        print(f\"Healthy - Mean: {healthy['PPE'].mean():.4f}, Std: {healthy['PPE'].std():.4f}\")\n",
        "        print(f\"Parkinson's - Mean: {parkinsons['PPE'].mean():.4f}, Std: {parkinsons['PPE'].std():.4f}\")\n",
        "\n",
        "    # Key Features Distribution\n",
        "    key_features = ['MDVP:Fo(Hz)', 'MDVP:Jitter(%)', 'MDVP:Shimmer',\n",
        "                    'HNR', 'RPDE', 'DFA']\n",
        "\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, col in enumerate(key_features):\n",
        "        if col in df.columns:\n",
        "            axes[i].hist(df[col], bins=30, color='#3498db', alpha=0.7, edgecolor='black')\n",
        "            axes[i].set_title(col, fontweight='bold')\n",
        "            axes[i].set_xlabel('Value')\n",
        "            axes[i].set_ylabel('Frequency')\n",
        "            axes[i].grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{eda_dir}/03_feature_distributions.png\", dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(\"Saved: 03_feature_distributions.png\")\n",
        "\n",
        "    # Features vs Target (Box plots)\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, col in enumerate(key_features):\n",
        "        if col in df.columns:\n",
        "            data_to_plot = [df[df[target_col] == 0][col].dropna(),\n",
        "                           df[df[target_col] == 1][col].dropna()]\n",
        "            bp = axes[i].boxplot(data_to_plot, labels=['Healthy', 'Parkinson\\'s'],\n",
        "                                patch_artist=True)\n",
        "            for patch, color in zip(bp['boxes'], ['#3498db', '#e74c3c']):\n",
        "                patch.set_facecolor(color)\n",
        "                patch.set_alpha(0.7)\n",
        "            axes[i].set_title(col, fontweight='bold')\n",
        "            axes[i].set_ylabel('Value')\n",
        "            axes[i].grid(alpha=0.3, axis='y')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{eda_dir}/04_features_vs_target.png\", dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(\"Saved: 04_features_vs_target.png\")\n",
        "\n",
        "    # Correlation Heatmap\n",
        "    numeric_df = df.select_dtypes(include=[np.number])\n",
        "\n",
        "    if target_col in numeric_df.columns and len(numeric_df.columns) > 1:\n",
        "        correlations = numeric_df.corr()[target_col].abs().sort_values(ascending=False)\n",
        "        top_n = min(16, len(correlations))\n",
        "        top_features = correlations.head(top_n).index.tolist()\n",
        "\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        sns.heatmap(numeric_df[top_features].corr(), annot=True, fmt='.2f',\n",
        "                    cmap='RdYlBu_r', center=0, square=True, linewidths=1,\n",
        "                    cbar_kws={\"shrink\": 0.8})\n",
        "        plt.title(f'Correlation Heatmap - Top {top_n} Features',\n",
        "                 fontsize=14, fontweight='bold')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{eda_dir}/05_correlation_heatmap.png\", dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "        print(\"Saved: 05_correlation_heatmap.png\")\n",
        "\n",
        "        # Print top correlations\n",
        "        print(f\"\\nTop 10 features correlated with {target_col}:\")\n",
        "        for idx, (feat, corr) in enumerate(correlations.head(11).items(), 1):\n",
        "            if feat != target_col:\n",
        "                print(f\" {idx}. {feat}: {corr:.4f}\")\n",
        "\n",
        "    print(f\"\\nAll EDA plots saved to: {eda_dir}\")"
      ],
      "metadata": {
        "id": "kanpLNY9fCgI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1eLclFwAt1GT"
      },
      "outputs": [],
      "source": [
        "# SECTION 4: FEATURE ENGINEERING\n",
        "def create_engineered_features(df):\n",
        "    print(\"\\n4. FEATURE ENGINEERING\\n\")\n",
        "\n",
        "    df_new = df.copy()\n",
        "\n",
        "    # Jitter-Shimmer interaction\n",
        "    jitter_cols = [col for col in df.columns if 'Jitter' in col or 'jitter' in col.lower()]\n",
        "    shimmer_cols = [col for col in df.columns if 'Shimmer' in col or 'shimmer' in col.lower()]\n",
        "\n",
        "    if jitter_cols and shimmer_cols:\n",
        "        df_new['jitter_shimmer_product'] = df[jitter_cols].mean(axis=1) * df[shimmer_cols].mean(axis=1)\n",
        "        print(\"Created: jitter_shimmer_product\")\n",
        "\n",
        "    if jitter_cols:\n",
        "        df_new['avg_jitter'] = df[jitter_cols].mean(axis=1)\n",
        "        print(\"Created: avg_jitter\")\n",
        "\n",
        "    if shimmer_cols:\n",
        "        df_new['avg_shimmer'] = df[shimmer_cols].mean(axis=1)\n",
        "        print(\"Created: avg_shimmer\")\n",
        "\n",
        "    if 'HNR' in df.columns and 'NHR' in df.columns:\n",
        "        df_new['hnr_nhr_ratio'] = df['HNR'] / (df['NHR'] + 1e-10)\n",
        "        print(\"Created: hnr_nhr_ratio\")\n",
        "\n",
        "    if 'MDVP:Fhi(Hz)' in df.columns and 'MDVP:Flo(Hz)' in df.columns:\n",
        "        df_new['frequency_range'] = df['MDVP:Fhi(Hz)'] - df['MDVP:Flo(Hz)']\n",
        "        print(\"Created: frequency_range\")\n",
        "\n",
        "    if 'MDVP:Fo(Hz)' in df.columns and 'MDVP:Fhi(Hz)' in df.columns and 'MDVP:Flo(Hz)' in df.columns:\n",
        "        df_new['frequency_cv'] = (df['MDVP:Fhi(Hz)'] - df['MDVP:Flo(Hz)']) / (df['MDVP:Fo(Hz)'] + 1e-10)\n",
        "        print(\"Created: frequency_cv\")\n",
        "\n",
        "    if jitter_cols and shimmer_cols:\n",
        "        df_new['voice_perturbation_index'] = (df[jitter_cols].mean(axis=1) +\n",
        "                                               df[shimmer_cols].mean(axis=1)) / 2\n",
        "        print(\"Created: voice_perturbation_index\")\n",
        "\n",
        "    if 'spread1' in df.columns and 'spread2' in df.columns:\n",
        "        df_new['spread_interaction'] = df['spread1'] * df['spread2']\n",
        "        print(\"Created: spread_interaction\")\n",
        "\n",
        "    if 'DFA' in df.columns and 'PPE' in df.columns:\n",
        "        df_new['dfa_ppe_product'] = df['DFA'] * df['PPE']\n",
        "        print(\"Created: dfa_ppe_product\")\n",
        "\n",
        "    print(f\"\\nTotal features after engineering: {df_new.shape[1] - 1}\")\n",
        "\n",
        "    return df_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iZ7OXlGut1Nz"
      },
      "outputs": [],
      "source": [
        "def validate_target(df, target):\n",
        "    print(\"\\n5. TARGET VALIDATION\\n\")\n",
        "\n",
        "    if target not in df.columns:\n",
        "        raise Exception(f\"Target column '{target}' not found in dataset.\")\n",
        "    if df[target].nunique() < 2:\n",
        "        raise Exception(\"Target has less than 2 classes. Classification impossible.\")\n",
        "\n",
        "    print(f\"Target variable: {target}\")\n",
        "    print(f\"Number of classes: {df[target].nunique()}\")\n",
        "    print(f\"\\nClass distribution:\")\n",
        "    counts = df[target].value_counts().sort_index()\n",
        "    labels = {0: \"Healthy\", 1: \"Parkinson's\"}\n",
        "    for label, count in counts.items():\n",
        "        print(f\"  {labels.get(label, label)}: {count} ({count/len(df)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HamjkEPvtfeV"
      },
      "outputs": [],
      "source": [
        "# SECTION 6: FEATURE SCALING\n",
        "def encode_and_scale(df, target):\n",
        "    print(\"\\n6. FEATURE SCALING\\n\")\n",
        "\n",
        "    X = df.drop(columns=[target])\n",
        "    y = df[target]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    print(f\"Final feature count: {X.shape[1]}\")\n",
        "    print(f\"Features standardized using StandardScaler\")\n",
        "\n",
        "    return X, X_scaled, y, scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2rCW7gkJtfoU"
      },
      "outputs": [],
      "source": [
        "# SECTION 7: TRAIN-TEST SPLIT\n",
        "def safe_train_test_split(X, y, test_size=0.2):\n",
        "    print(\"\\n7. TRAIN-TEST SPLIT\\n\")\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, stratify=y, random_state=42\n",
        "    )\n",
        "\n",
        "    print(f\"Split ratio: {int((1-test_size)*100)}/{int(test_size*100)}\")\n",
        "    print(f\"Training set: {len(X_train)} samples\")\n",
        "    print(f\"Test set: {len(X_test)} samples\")\n",
        "    print(f\"\\nClass distribution in training set:\")\n",
        "    train_counts = y_train.value_counts().sort_index()\n",
        "    labels = {0: \"Healthy\", 1: \"Parkinson's\"}\n",
        "    for label, count in train_counts.items():\n",
        "        print(f\"  {labels.get(label, label)}: {count} ({count/len(y_train)*100:.1f}%)\")\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "lozsz3GjtfsJ"
      },
      "outputs": [],
      "source": [
        "# SECTION 8: AGGRESSIVE HYPERPARAMETER TUNING TO PREVENT OVERFITTING\n",
        "def tune_hyperparameters(X_train, y_train):\n",
        "    print(\"\\n8.HYPERPARAMETER TUNING\\n\")\n",
        "\n",
        "    tuned_models = {}\n",
        "    tuning_results = []\n",
        "\n",
        "    # Random Forest with VERY STRONG regularization\n",
        "    print(\"Tuning Random Forest with regularization...\")\n",
        "    rf_param_grid = {\n",
        "        'n_estimators': [50, 100],  # Fewer trees\n",
        "        'max_depth': [3, 5, 7],  # Very shallow trees\n",
        "        'min_samples_split': [20, 30, 40],  # Much higher split requirement\n",
        "        'min_samples_leaf': [10, 15, 20],  # Much higher leaf requirement\n",
        "        'max_features': ['sqrt', 'log2'],  # Limit features per split\n",
        "        'min_impurity_decrease': [0.01, 0.02],  # Require minimum improvement\n",
        "        'class_weight': ['balanced']\n",
        "    }\n",
        "\n",
        "    rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "    rf_grid = GridSearchCV(rf, rf_param_grid, cv=5, scoring='f1', n_jobs=-1, verbose=0)\n",
        "\n",
        "    start_time = time.time()\n",
        "    rf_grid.fit(X_train, y_train)\n",
        "    rf_time = time.time() - start_time\n",
        "\n",
        "    tuned_models['Random_Forest'] = rf_grid.best_estimator_\n",
        "    print(f\"Best RF parameters: {rf_grid.best_params_}\")\n",
        "    print(f\"Best CV score: {rf_grid.best_score_:.4f}\")\n",
        "    print(f\"Training time: {rf_time:.2f} seconds\\n\")\n",
        "\n",
        "    tuning_results.append({\n",
        "        'Model': 'Random_Forest',\n",
        "        'Best_Params': rf_grid.best_params_,\n",
        "        'Best_CV_Score': rf_grid.best_score_,\n",
        "        'Training_Time': rf_time\n",
        "    })\n",
        "\n",
        "    # Logistic Regression with STRONG regularization\n",
        "    print(\"Tuning Logistic Regression with strong regularization...\")\n",
        "    lr_param_grid = {\n",
        "        'C': [0.001, 0.01, 0.1, 1.0],  # Strong regularization (lower C)\n",
        "        'penalty': ['l1', 'l2', 'elasticnet'],  # All penalty types\n",
        "        'solver': ['saga'],  # Supports all penalties\n",
        "        'l1_ratio': [0.3, 0.5, 0.7],  # For elasticnet\n",
        "        'class_weight': ['balanced'],\n",
        "        'max_iter': [2000]\n",
        "    }\n",
        "\n",
        "    lr = LogisticRegression(random_state=42)\n",
        "    lr_grid = GridSearchCV(lr, lr_param_grid, cv=5, scoring='f1', n_jobs=-1, verbose=0)\n",
        "\n",
        "    start_time = time.time()\n",
        "    lr_grid.fit(X_train, y_train)\n",
        "    lr_time = time.time() - start_time\n",
        "\n",
        "    tuned_models['Logistic_Regression'] = lr_grid.best_estimator_\n",
        "    print(f\"Best LR parameters: {lr_grid.best_params_}\")\n",
        "    print(f\"Best CV score: {lr_grid.best_score_:.4f}\")\n",
        "    print(f\"Training time: {lr_time:.2f} seconds\\n\")\n",
        "\n",
        "    tuning_results.append({\n",
        "        'Model': 'Logistic_Regression',\n",
        "        'Best_Params': lr_grid.best_params_,\n",
        "        'Best_CV_Score': lr_grid.best_score_,\n",
        "        'Training_Time': lr_time\n",
        "    })\n",
        "\n",
        "\n",
        "\n",
        "    # Save tuning results\n",
        "    df_tuning = pd.DataFrame(tuning_results)\n",
        "    df_tuning.to_csv(f\"{OUTPUT_DIR}/hyperparameter_tuning.csv\", index=False)\n",
        "    print(f\"Hyperparameter tuning results saved to: {OUTPUT_DIR}/hyperparameter_tuning.csv\")\n",
        "\n",
        "    return tuned_models, tuning_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "gPscNyD5tgEa"
      },
      "outputs": [],
      "source": [
        "# SECTION 9: MODEL EVALUATION WITH OVERFITTING ANALYSIS\n",
        "def evaluate_models(models, X_train, X_test, y_train, y_test):\n",
        "    print(\"\\n9. MODEL EVALUATION WITH OVERFITTING ANALYSIS\\n\")\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for name, model in models.items():\n",
        "        print(f\"\\nEvaluating {name}...\")\n",
        "\n",
        "        # Training set performance\n",
        "        y_train_pred = model.predict(X_train)\n",
        "        train_acc = accuracy_score(y_train, y_train_pred)\n",
        "\n",
        "        # Test set performance\n",
        "        y_test_pred = model.predict(X_test)\n",
        "        test_acc = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "        # Calculate overfitting metric\n",
        "        overfitting_gap = train_acc - test_acc\n",
        "\n",
        "        # Other metrics\n",
        "        prec = precision_score(y_test, y_test_pred, zero_division=0)\n",
        "        rec = recall_score(y_test, y_test_pred, zero_division=0)\n",
        "        f1 = f1_score(y_test, y_test_pred, zero_division=0)\n",
        "\n",
        "        # ROC AUC\n",
        "        if hasattr(model, \"predict_proba\"):\n",
        "            y_prob = model.predict_proba(X_test)[:, 1]\n",
        "            roc_auc = roc_auc_score(y_test, y_prob)\n",
        "        else:\n",
        "            roc_auc = None\n",
        "\n",
        "        cm = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        # Print metrics\n",
        "        print(f\"Training Accuracy:  {train_acc:.4f}\")\n",
        "        print(f\"Test Accuracy:      {test_acc:.4f}\")\n",
        "        print(f\"Overfitting Gap:    {overfitting_gap:.4f}\")\n",
        "        print(f\"Precision:          {prec:.4f}\")\n",
        "        print(f\"Recall:             {rec:.4f}\")\n",
        "        print(f\"F1 Score:           {f1:.4f}\")\n",
        "        if roc_auc:\n",
        "            print(f\"ROC AUC:            {roc_auc:.4f}\")\n",
        "        print(f\"\\nConfusion Matrix:\")\n",
        "        print(f\"                 Predicted\")\n",
        "        print(f\"                 Healthy  Parkinson's\")\n",
        "        print(f\"Actual Healthy      {cm[0][0]:3d}       {cm[0][1]:3d}\")\n",
        "        print(f\"       Parkinson's  {cm[1][0]:3d}       {cm[1][1]:3d}\")\n",
        "\n",
        "        # Learning curves\n",
        "        plot_learning_curve(model, X_train, y_train, name)\n",
        "\n",
        "        results.append({\n",
        "            \"Model\": name,\n",
        "            \"Train_Accuracy\": train_acc,\n",
        "            \"Test_Accuracy\": test_acc,\n",
        "            \"Overfitting_Gap\": overfitting_gap,\n",
        "            \"Precision\": prec,\n",
        "            \"Recall\": rec,\n",
        "            \"F1_Score\": f1,\n",
        "            \"ROC_AUC\": roc_auc if roc_auc else 0,\n",
        "            \"True_Negatives\": int(cm[0][0]),\n",
        "            \"False_Positives\": int(cm[0][1]),\n",
        "            \"False_Negatives\": int(cm[1][0]),\n",
        "            \"True_Positives\": int(cm[1][1])\n",
        "        })\n",
        "\n",
        "    df_results = pd.DataFrame(results)\n",
        "    df_results.to_csv(f\"{OUTPUT_DIR}/model_metrics.csv\", index=False)\n",
        "    print(f\"\\nDetailed metrics saved to: {OUTPUT_DIR}/model_metrics.csv\")\n",
        "\n",
        "    best_model_name = df_results.loc[df_results['Test_Accuracy'].idxmax(), 'Model']\n",
        "    best_accuracy = df_results['Test_Accuracy'].max()\n",
        "\n",
        "    print(\"\\n\\nMODEL COMPARISON SUMMARY\\n\")\n",
        "    print(f\"{'Model':<25} {'Train_Acc':<12} {'Test_Acc':<12} {'Gap':<10} {'F1':<10}\")\n",
        "    print(\"-\" * 75)\n",
        "    for _, row in df_results.iterrows():\n",
        "        print(f\"{row['Model']:<25} {row['Train_Accuracy']:<12.4f} {row['Test_Accuracy']:<12.4f} \"\n",
        "              f\"{row['Overfitting_Gap']:<10.4f} {row['F1_Score']:<10.4f}\")\n",
        "\n",
        "    print(f\"\\nBEST MODEL: {best_model_name} (Test Accuracy: {best_accuracy:.4f})\")\n",
        "\n",
        "    return df_results, best_model_name"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learning_curve(model, X_train, y_train, model_name):\n",
        "    train_sizes, train_scores, val_scores = learning_curve(\n",
        "        model, X_train, y_train, cv=5, n_jobs=-1,\n",
        "        train_sizes=np.linspace(0.1, 1.0, 10), scoring='accuracy'\n",
        "    )\n",
        "\n",
        "    train_mean = np.mean(train_scores, axis=1)\n",
        "    train_std = np.std(train_scores, axis=1)\n",
        "    val_mean = np.mean(val_scores, axis=1)\n",
        "    val_std = np.std(val_scores, axis=1)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(train_sizes, train_mean, label='Training score', color='blue', marker='o')\n",
        "    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.15, color='blue')\n",
        "    plt.plot(train_sizes, val_mean, label='Cross-validation score', color='red', marker='s')\n",
        "    plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.15, color='red')\n",
        "    plt.xlabel('Training Set Size')\n",
        "    plt.ylabel('Accuracy Score')\n",
        "    plt.title(f'Learning Curve - {model_name}', fontweight='bold')\n",
        "    plt.legend(loc='best')\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{OUTPUT_DIR}/learning_curve_{model_name}.png\", dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"Saved learning curve for {model_name}\")\n"
      ],
      "metadata": {
        "id": "U5Ft2ZrOf6UT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SECTION 10: RESOURCE USAGE ANALYSIS\n",
        "def measure_resource_usage(models, X_test):\n",
        "    print(\"\\n10. RESOURCE USAGE ANALYSIS\\n\")\n",
        "\n",
        "    process = psutil.Process()\n",
        "    resource_results = []\n",
        "\n",
        "    for name, model in models.items():\n",
        "        # Measure inference time\n",
        "        start_time = time.time()\n",
        "        model.predict(X_test)\n",
        "        inference_time = time.time() - start_time\n",
        "\n",
        "        # Measure memory\n",
        "        mem_info = process.memory_info()\n",
        "        memory_mb = mem_info.rss / (1024 * 1024)\n",
        "\n",
        "        print(f\"{name}:\")\n",
        "        print(f\"  Inference time (test set): {inference_time:.4f} seconds\")\n",
        "        print(f\"  Memory usage: {memory_mb:.2f} MB\")\n",
        "\n",
        "        resource_results.append({\n",
        "            'Model': name,\n",
        "            'Inference_Time_Seconds': inference_time,\n",
        "            'Memory_MB': memory_mb\n",
        "        })\n",
        "\n",
        "    df_resources = pd.DataFrame(resource_results)\n",
        "    df_resources.to_csv(f\"{OUTPUT_DIR}/resource_usage.csv\", index=False)\n",
        "    print(f\"\\nResource usage saved to: {OUTPUT_DIR}/resource_usage.csv\")\n",
        "\n",
        "    return df_resources"
      ],
      "metadata": {
        "id": "Qmv4c6eIgACO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KXoPBR0GtgKw"
      },
      "outputs": [],
      "source": [
        "# SECTION 11: FEATURE IMPORTANCE\n",
        "def plot_feature_importance(model, feature_names, model_name):\n",
        "    if hasattr(model, 'feature_importances_'):\n",
        "        importances = model.feature_importances_\n",
        "        indices = np.argsort(importances)[-15:]\n",
        "\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        plt.barh(range(len(indices)), importances[indices], color='#3498db', alpha=0.7)\n",
        "        plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
        "        plt.xlabel('Feature Importance')\n",
        "        plt.title(f'Top 15 Feature Importances - {model_name}', fontweight='bold')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{OUTPUT_DIR}/feature_importance_{model_name}.png\", dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "        print(f\"Saved feature importance plot for {model_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "sV4mMbnItgN2"
      },
      "outputs": [],
      "source": [
        "# SECTION 12: SAVE ARTIFACTS\n",
        "def save_artifacts(models, scaler, best_model_name, feature_names):\n",
        "    print(\"\\n12. SAVING ARTIFACTS\\n\")\n",
        "\n",
        "    for name, model in models.items():\n",
        "        filepath = f\"{OUTPUT_DIR}/{name}.pkl\"\n",
        "        with open(filepath, \"wb\") as f:\n",
        "            pickle.dump(model, f)\n",
        "        print(f\"Saved: {name}.pkl\")\n",
        "\n",
        "        if name == 'Random_Forest':\n",
        "            plot_feature_importance(model, feature_names, name)\n",
        "\n",
        "    with open(f\"{OUTPUT_DIR}/scaler.pkl\", \"wb\") as f:\n",
        "        pickle.dump(scaler, f)\n",
        "    print(f\"Saved: scaler.pkl\")\n",
        "\n",
        "    with open(f\"{OUTPUT_DIR}/best_model.pkl\", \"wb\") as f:\n",
        "        pickle.dump(models[best_model_name], f)\n",
        "    print(f\"Saved: best_model.pkl ({best_model_name})\")\n",
        "\n",
        "    with open(f\"{OUTPUT_DIR}/feature_names.pkl\", \"wb\") as f:\n",
        "        pickle.dump(feature_names, f)\n",
        "    print(f\"Saved: feature_names.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkSeWuZ2tgRG",
        "outputId": "65a0aa99-9f45-44ba-8c07-bdd1088caad7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully\n",
            "Shape: (195, 24) (rows x columns)\n",
            "Features: 24\n",
            "\n",
            "Data Types:\n",
            "float64    22\n",
            "object      1\n",
            "int64       1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "First 5 rows:\n",
            "             name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
            "0  phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
            "1  phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
            "2  phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
            "3  phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
            "4  phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
            "\n",
            "   MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n",
            "0           0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n",
            "1           0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n",
            "2           0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n",
            "3           0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n",
            "4           0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n",
            "\n",
            "   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
            "0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
            "1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
            "2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
            "3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
            "4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
            "\n",
            "    spread2        D2       PPE  \n",
            "0  0.266482  2.301442  0.284654  \n",
            "1  0.335590  2.486855  0.368674  \n",
            "2  0.311173  2.342259  0.332634  \n",
            "3  0.334147  2.405554  0.368975  \n",
            "4  0.234513  2.332180  0.410335  \n",
            "\n",
            "[5 rows x 24 columns]\n",
            "\n",
            "4. FEATURE ENGINEERING\n",
            "\n",
            "Created: jitter_shimmer_product\n",
            "Created: avg_jitter\n",
            "Created: avg_shimmer\n",
            "Created: hnr_nhr_ratio\n",
            "Created: frequency_range\n",
            "Created: frequency_cv\n",
            "Created: voice_perturbation_index\n",
            "Created: spread_interaction\n",
            "Created: dfa_ppe_product\n",
            "\n",
            "Total features after engineering: 32\n",
            "\n",
            "3. EXPLORATORY DATA ANALYSIS\n",
            "Saved: 01_target_distribution.png\n",
            "Saved: 02_ppe_scatterplot.png (PPE scatterplot)\n",
            "\n",
            "PPE Statistics:\n",
            "Healthy - Mean: 0.1230, Std: 0.0448\n",
            "Parkinson's - Mean: 0.2338, Std: 0.0843\n",
            "Saved: 03_feature_distributions.png\n",
            "Saved: 04_features_vs_target.png\n",
            "Saved: 05_correlation_heatmap.png\n",
            "\n",
            "Top 10 features correlated with status:\n",
            " 2. spread1: 0.5648\n",
            " 3. PPE: 0.5310\n",
            " 4. dfa_ppe_product: 0.5240\n",
            " 5. spread2: 0.4548\n",
            " 6. MDVP:Fo(Hz): 0.3835\n",
            " 7. MDVP:Flo(Hz): 0.3802\n",
            " 8. MDVP:Shimmer: 0.3674\n",
            " 9. MDVP:APQ: 0.3643\n",
            " 10. HNR: 0.3615\n",
            " 11. hnr_nhr_ratio: 0.3582\n",
            "\n",
            "All EDA plots saved to: parkinsons_outputs/eda_plots\n",
            "\n",
            "2. DATA CLEANING WITH FEATURE SELECTION\n",
            "\n",
            "Before cleaning: (195, 33)\n",
            "Removed 'name' column (identifier)\n",
            "Removed 0 duplicate rows\n",
            "No missing values found\n",
            "\n",
            "After basic cleaning: (195, 32)\n",
            "CORRELATION-BASED FEATURE SELECTION\n",
            "\n",
            "Calculating correlations with target variable...\n",
            "\n",
            "Top 15 Features by Correlation with 'status':\n",
            "------------------------------------------------------------\n",
            "    1. spread1                        | Correlation: 0.5648\n",
            "    2. PPE                            | Correlation: 0.5310\n",
            "    3. dfa_ppe_product                | Correlation: 0.5240\n",
            "    4. spread2                        | Correlation: 0.4548\n",
            "    5. MDVP:Fo(Hz)                    | Correlation: 0.3835\n",
            "    6. MDVP:Flo(Hz)                   | Correlation: 0.3802\n",
            "    7. MDVP:Shimmer                   | Correlation: 0.3674\n",
            "    8. MDVP:APQ                       | Correlation: 0.3643\n",
            "    9. HNR                            | Correlation: 0.3615\n",
            "   10. hnr_nhr_ratio                  | Correlation: 0.3582\n",
            "   11. avg_shimmer                    | Correlation: 0.3536\n",
            "   12. voice_perturbation_index       | Correlation: 0.3526\n",
            "   13. Shimmer:APQ5                   | Correlation: 0.3511\n",
            "   14. MDVP:Shimmer(dB)               | Correlation: 0.3507\n",
            "   15. Shimmer:APQ3                   | Correlation: 0.3476\n",
            "FEATURE SELECTION SUMMARY\n",
            "Original features:  31\n",
            "Selected features:  15\n",
            "Reduction:  16 features removed (51.6%)\n",
            "\n",
            "Final shape: (195, 16)\n",
            "Final features: 15 (excluding target)\n",
            "\n",
            "5. TARGET VALIDATION\n",
            "\n",
            "Target variable: status\n",
            "Number of classes: 2\n",
            "\n",
            "Class distribution:\n",
            "  Healthy: 48 (24.6%)\n",
            "  Parkinson's: 147 (75.4%)\n",
            "\n",
            "6. FEATURE SCALING\n",
            "\n",
            "Final feature count: 15\n",
            "Features standardized using StandardScaler\n",
            "\n",
            "7. TRAIN-TEST SPLIT\n",
            "\n",
            "Split ratio: 80/20\n",
            "Training set: 156 samples\n",
            "Test set: 39 samples\n",
            "\n",
            "Class distribution in training set:\n",
            "  Healthy: 38 (24.4%)\n",
            "  Parkinson's: 118 (75.6%)\n",
            "\n",
            "8. AGGRESSIVE HYPERPARAMETER TUNING (ANTI-OVERFITTING)\n",
            "\n",
            "Tuning Random Forest with aggressive regularization...\n",
            "Best RF parameters: {'class_weight': 'balanced', 'max_depth': 3, 'max_features': 'sqrt', 'min_impurity_decrease': 0.01, 'min_samples_leaf': 10, 'min_samples_split': 20, 'n_estimators': 50}\n",
            "Best CV score: 0.8791\n",
            "Training time: 170.67 seconds\n",
            "\n",
            "Tuning Logistic Regression with strong regularization...\n",
            "Best LR parameters: {'C': 1.0, 'class_weight': 'balanced', 'l1_ratio': 0.3, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga'}\n",
            "Best CV score: 0.8737\n",
            "Training time: 2.61 seconds\n",
            "\n",
            "Hyperparameter tuning results saved to: parkinsons_outputs/hyperparameter_tuning.csv\n",
            "\n",
            "9. MODEL EVALUATION WITH OVERFITTING ANALYSIS\n",
            "\n",
            "\n",
            "Evaluating Random_Forest...\n",
            "Training Accuracy:  0.8397\n",
            "Test Accuracy:      0.7692\n",
            "Overfitting Gap:    0.0705 (potential overfitting)\n",
            "Precision:          0.9545\n",
            "Recall:             0.7241\n",
            "F1 Score:           0.8235\n",
            "ROC AUC:            0.9034\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted\n",
            "                 Healthy  Parkinson's\n",
            "Actual Healthy        9         1\n",
            "       Parkinson's    8        21\n",
            "Saved learning curve for Random_Forest\n",
            "\n",
            "Evaluating Logistic_Regression...\n",
            "Training Accuracy:  0.8526\n",
            "Test Accuracy:      0.7692\n",
            "Overfitting Gap:    0.0833 (potential overfitting)\n",
            "Precision:          0.9167\n",
            "Recall:             0.7586\n",
            "F1 Score:           0.8302\n",
            "ROC AUC:            0.9138\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted\n",
            "                 Healthy  Parkinson's\n",
            "Actual Healthy        8         2\n",
            "       Parkinson's    7        22\n",
            "Saved learning curve for Logistic_Regression\n",
            "\n",
            "Detailed metrics saved to: parkinsons_outputs/model_metrics.csv\n",
            "\n",
            "\n",
            "MODEL COMPARISON SUMMARY\n",
            "\n",
            "Model                     Train_Acc    Test_Acc     Gap        F1        \n",
            "---------------------------------------------------------------------------\n",
            "Random_Forest             0.8397       0.7692       0.0705     0.8235    \n",
            "Logistic_Regression       0.8526       0.7692       0.0833     0.8302    \n",
            "\n",
            "BEST MODEL: Random_Forest (Test Accuracy: 0.7692)\n",
            "\n",
            "10. RESOURCE USAGE ANALYSIS\n",
            "\n",
            "Random_Forest:\n",
            "  Inference time (test set): 0.0236 seconds\n",
            "  Memory usage: 373.09 MB\n",
            "Logistic_Regression:\n",
            "  Inference time (test set): 0.0004 seconds\n",
            "  Memory usage: 373.09 MB\n",
            "\n",
            "Resource usage saved to: parkinsons_outputs/resource_usage.csv\n",
            "\n",
            "12. SAVING ARTIFACTS\n",
            "\n",
            "Saved: Random_Forest.pkl\n",
            "Saved feature importance plot for Random_Forest\n",
            "Saved: Logistic_Regression.pkl\n",
            "Saved: scaler.pkl\n",
            "Saved: best_model.pkl (Random_Forest)\n",
            "Saved: feature_names.pkl\n",
            "\n",
            "All outputs saved to: parkinsons_outputs/\n",
            "  - EDA plots in: parkinsons_outputs/eda_plots/\n",
            "  - Model metrics: parkinsons_outputs/model_metrics.csv\n",
            "  - Hyperparameter tuning: parkinsons_outputs/hyperparameter_tuning.csv\n",
            "  - Resource usage: parkinsons_outputs/resource_usage.csv\n",
            "  - Trained models: parkinsons_outputs/*.pkl\n"
          ]
        }
      ],
      "source": [
        "# MAIN EXECUTION\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "        # Load data\n",
        "  df = load_data(DATASET_PATH)\n",
        "\n",
        "        # Feature engineering\n",
        "  df = create_engineered_features(df)\n",
        "\n",
        "        # EDA\n",
        "  run_eda(df, TARGET_COLUMN)\n",
        "\n",
        "        #clean data\n",
        "  df = clean_data(df)\n",
        "\n",
        "        # Validate target\n",
        "  validate_target(df, TARGET_COLUMN)\n",
        "\n",
        "        # Encode and scale\n",
        "  X, X_scaled, y, scaler = encode_and_scale(df, TARGET_COLUMN)\n",
        "\n",
        "        # Train-test split\n",
        "  X_train, X_test, y_train, y_test = safe_train_test_split(X_scaled, y)\n",
        "\n",
        "        # Hyperparameter tuning\n",
        "  models, tuning_results = tune_hyperparameters(X_train, y_train)\n",
        "\n",
        "        # Evaluate models with overfitting analysis\n",
        "  results, best_model_name = evaluate_models(models, X_train, X_test, y_train, y_test)\n",
        "\n",
        "        # Resource usage analysis\n",
        "  resource_df = measure_resource_usage(models, X_test)\n",
        "\n",
        "        # Save artifacts\n",
        "  save_artifacts(models, scaler, best_model_name, X.columns.tolist())\n",
        "\n",
        "\n",
        "\n",
        "  print(f\"\\nAll outputs saved to: {OUTPUT_DIR}/\")\n",
        "  print(f\"  - EDA plots in: {OUTPUT_DIR}/eda_plots/\")\n",
        "  print(f\"  - Model metrics: {OUTPUT_DIR}/model_metrics.csv\")\n",
        "  print(f\"  - Hyperparameter tuning: {OUTPUT_DIR}/hyperparameter_tuning.csv\")\n",
        "  print(f\"  - Resource usage: {OUTPUT_DIR}/resource_usage.csv\")\n",
        "  print(f\"  - Trained models: {OUTPUT_DIR}/*.pkl\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1-mpLY5Qn792"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}